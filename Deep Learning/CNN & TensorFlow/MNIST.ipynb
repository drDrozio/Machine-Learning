{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-a839aeb82f4b>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Ishan SS\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Ishan SS\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Ishan SS\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Ishan SS\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Ishan SS\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000002686C414A48>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000002686D083188>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000002686D083508>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((55000, 784), (55000, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape, mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]), (10,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[0], mnist.train.labels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000, 10))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.test.images.shape, mnist.test.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.validation.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = mnist.train.images[400]\n",
    "image = np.array(image, dtype='float')\n",
    "image = image.reshape((28,28))\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input=784\n",
    "n_hidden_1=1600\n",
    "n_hidden_2=1600\n",
    "n_output=10\n",
    "\n",
    "weights={\n",
    "    'h1' : tf.Variable(tf.random_normal([n_input,n_hidden_1])),\n",
    "    'h2' : tf.Variable(tf.random_normal([n_hidden_1,n_hidden_2])),\n",
    "    'op' : tf.Variable(tf.random_normal([n_hidden_2,n_output]))\n",
    "}\n",
    "\n",
    "biases={\n",
    "    'h1' : tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'h2' : tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'op' : tf.Variable(tf.random_normal([n_output]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(784, 784) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(784, 784) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(784, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=(784,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_4:0' shape=(784,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_5:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_6:0' shape=(784, 1600) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_7:0' shape=(1600, 1600) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_8:0' shape=(1600, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_9:0' shape=(1600,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_10:0' shape=(1600,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_11:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()\n",
    "#All variables by default are trainable and thus the optimizer only chooses those variables which are trainable.\n",
    "#If we dont want a particular variable to be used in optimization we write- trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(x,weights,biases):\n",
    "    in_h1=tf.add(tf.matmul(x,weights['h1']),biases['h1'])\n",
    "    op_h1=tf.nn.relu(in_h1)\n",
    "    \n",
    "    in_h2=tf.add(tf.matmul(op_h1,weights['h2']),biases['h2'])\n",
    "    op_h2=tf.nn.relu(in_h2)\n",
    "    \n",
    "    op=tf.add(tf.matmul(op_h2,weights['op']),biases['op'])\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Add_5:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=tf.placeholder(\"float\",[None,n_input])\n",
    "y=tf.placeholder(tf.int32,[None,n_output])\n",
    "pred=forward_propagation(x,weights,biases)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean_2:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred ,labels=y))\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "optimize=optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(784, 784) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(784, 784) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(784, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=(784,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_4:0' shape=(784,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_5:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_6:0' shape=(784, 1600) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_7:0' shape=(1600, 1600) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_8:0' shape=(1600, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_9:0' shape=(1600,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_10:0' shape=(1600,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_11:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 294986.1792573929\n",
      "1 71520.94587147236\n",
      "2 36910.79714266356\n",
      "3 21702.1135483456\n",
      "4 14347.357352530584\n",
      "5 9888.149666721933\n",
      "6 8976.034806737402\n",
      "7 8189.476840791404\n",
      "8 7397.983735307478\n",
      "9 6991.846617314695\n",
      "10 6614.179242072569\n",
      "11 5590.301305555253\n",
      "12 4707.7592381341765\n",
      "13 5135.566641871334\n",
      "14 4353.274676332516\n",
      "15 3742.9952764944537\n",
      "16 3347.9008555842593\n",
      "17 4965.157938446384\n",
      "18 2876.327523001212\n",
      "19 3551.096806548671\n",
      "20 2888.213358838111\n",
      "21 2692.8109650981496\n",
      "22 2991.078530468637\n",
      "23 2365.497397683561\n",
      "24 3449.289495870471\n",
      "25 2413.025929812884\n",
      "26 1523.3095471036845\n",
      "27 2474.210523340769\n",
      "28 2012.3849466603995\n",
      "29 2306.5608729720116\n",
      "30 1734.0708887577057\n",
      "31 961.787576297158\n",
      "32 2070.1007939454867\n",
      "33 2125.6961192414165\n",
      "34 1797.4282768886674\n",
      "35 1330.672046005428\n",
      "36 1618.5736195106806\n",
      "37 1588.205555152148\n",
      "38 1291.6860921368793\n",
      "39 1573.7911644428968\n",
      "40 1616.8779155945779\n",
      "41 2036.4040793702006\n",
      "42 892.2417218610644\n",
      "43 1164.38434802399\n",
      "44 1334.888000779174\n",
      "45 1067.3002789579518\n",
      "46 749.211874619194\n",
      "47 1407.5237779057022\n",
      "48 1304.6108602845025\n",
      "49 760.3851562321181\n",
      "50 1020.5959921255708\n",
      "51 942.2239899565534\n",
      "52 1283.367149591446\n",
      "53 1184.0711771547794\n",
      "54 1177.464048128426\n",
      "55 874.7375837564468\n",
      "56 967.4798565208912\n",
      "57 897.1383878588676\n",
      "58 841.6180033907294\n",
      "59 948.1546439230442\n",
      "60 1146.0972434023413\n",
      "61 998.016928068595\n",
      "62 703.3445980548859\n",
      "63 668.3766811300302\n",
      "64 774.0298735493235\n",
      "65 930.414259757176\n",
      "66 912.2033793032169\n",
      "67 630.4976841360331\n",
      "68 592.4850459289155\n",
      "69 502.4120988249779\n",
      "70 826.4585401415825\n",
      "71 1015.1628397999015\n",
      "72 809.4961034679413\n",
      "73 523.1079615354538\n",
      "74 537.6487447957679\n",
      "75 1126.804185256362\n",
      "76 757.3415921330452\n",
      "77 579.6405992470682\n",
      "78 622.9809030815959\n",
      "79 587.6913230419159\n",
      "80 541.4543092000484\n",
      "81 849.4492995217443\n",
      "82 895.7765011856081\n",
      "83 583.467672675848\n",
      "84 311.2764737334642\n",
      "85 452.8756621479988\n",
      "86 830.0768864371092\n",
      "87 542.0802507000044\n",
      "88 529.8482457660139\n",
      "89 652.6447357088327\n",
      "90 631.5122780874372\n",
      "91 444.2684666919629\n",
      "92 736.666785860667\n",
      "93 410.3086571395397\n",
      "94 350.0751560330391\n",
      "95 577.7746723042801\n",
      "96 599.906248316227\n",
      "97 613.1511666737497\n",
      "98 756.9475782811642\n",
      "99 191.38189806044102\n",
      "100 617.0111604961276\n",
      "101 558.7723474651575\n",
      "102 716.7445273962803\n",
      "103 326.34238312414334\n",
      "104 254.14558248221874\n",
      "105 302.94269558787346\n",
      "106 773.2720541311428\n",
      "107 425.1587626099582\n",
      "108 386.89307871460915\n",
      "109 502.2615050372481\n",
      "110 600.5028610825539\n",
      "111 434.7364484630525\n",
      "112 119.14351683855057\n",
      "113 214.218424372375\n",
      "114 889.7840055525303\n",
      "115 668.724495430279\n",
      "116 447.05211973593396\n",
      "117 358.7582969516516\n",
      "118 414.64650382101536\n",
      "119 434.36851049900054\n",
      "120 595.8081697869301\n",
      "121 496.414866566658\n",
      "122 305.950676766166\n",
      "123 300.35383155442196\n",
      "124 472.04498936235905\n",
      "125 382.0354632418748\n",
      "126 470.93518647790535\n",
      "127 618.8590397972366\n",
      "128 357.0754731022753\n",
      "129 179.19574220478535\n",
      "130 698.220836076307\n",
      "131 307.8477738201618\n",
      "132 187.708926320076\n",
      "133 740.2532386112213\n",
      "134 200.26761040091515\n",
      "135 332.4239653348923\n",
      "136 268.6613509953022\n",
      "137 652.0489377379417\n",
      "138 431.50877231717106\n",
      "139 222.46923586438584\n",
      "140 201.22441491482294\n",
      "141 354.28287237882614\n",
      "142 533.3511087180073\n",
      "143 344.01620134711266\n",
      "144 425.2831933507207\n",
      "145 425.6837708950043\n",
      "146 173.92288380861282\n",
      "147 253.47802710533142\n",
      "148 147.8476436138153\n",
      "149 434.3941855099256\n",
      "150 239.5883400440216\n",
      "151 511.1252331286669\n",
      "152 320.6470472502432\n",
      "153 292.59420120716095\n",
      "154 345.4902052799814\n",
      "155 157.39724892377853\n",
      "156 220.0026019042998\n",
      "157 412.34211844205856\n",
      "158 404.83247352950275\n",
      "159 377.8121748864651\n",
      "160 618.4241660964486\n",
      "161 132.58246558904648\n",
      "162 501.8258705623448\n",
      "163 234.08113002538678\n",
      "164 304.2769398338007\n",
      "165 332.721509724297\n",
      "166 224.42711612582207\n",
      "167 65.9732905626297\n",
      "168 340.57160836458206\n",
      "169 264.1110768318176\n",
      "170 520.9053545892239\n",
      "171 339.89061807870837\n",
      "172 404.12604466080666\n",
      "173 123.8681526184082\n",
      "174 132.29606840014458\n",
      "175 186.3240830898285\n",
      "176 431.1971624791622\n",
      "177 494.97495831921697\n",
      "178 329.09353404678404\n",
      "179 234.73227405548096\n",
      "180 189.15211049257752\n",
      "181 147.36934340000153\n",
      "182 162.033960044384\n",
      "183 288.8474819010662\n",
      "184 294.2140142917633\n",
      "185 359.5608243999304\n",
      "186 94.98674699664116\n",
      "187 125.47610330581665\n",
      "188 204.44862163066864\n",
      "189 43.680853843688965\n",
      "190 69.04125547409058\n",
      "191 608.76937456429\n",
      "192 597.394031525746\n",
      "193 494.29076627731325\n",
      "194 174.91330020222813\n",
      "195 113.41653841733932\n",
      "196 185.22804951667786\n",
      "197 268.5126962065697\n",
      "198 424.4238064335659\n",
      "199 336.1248092651367\n",
      "200 252.48040139122168\n",
      "201 273.23515069842335\n",
      "202 385.38344022631645\n",
      "203 186.7707289512473\n",
      "204 64.46271502971649\n",
      "205 367.33159428834915\n",
      "206 206.63393609705955\n",
      "207 445.3016944080591\n",
      "208 553.8784088643733\n",
      "209 132.19341778755188\n",
      "210 555.449139431119\n",
      "211 85.38904345035553\n",
      "212 189.6228523905138\n",
      "213 581.9655896499753\n",
      "214 202.5248839855194\n",
      "215 22.00542962551117\n",
      "216 173.70443987846375\n",
      "217 189.58309364978163\n",
      "218 338.9834334552288\n",
      "219 192.6713591068983\n",
      "220 275.861194537438\n",
      "221 302.1354216337204\n",
      "222 192.94315135478973\n",
      "223 267.78384209394454\n",
      "224 235.28595572616905\n",
      "225 121.17176753282547\n",
      "226 308.53345223719134\n",
      "227 485.17453610897064\n",
      "228 221.8353214263916\n",
      "229 195.62181121706962\n",
      "230 159.54268065094948\n",
      "231 231.6472125686705\n",
      "232 218.8982596322894\n",
      "233 163.3936220407486\n",
      "234 279.0882344841957\n",
      "235 183.84789943695068\n",
      "236 232.00849080085754\n",
      "237 434.58360372763127\n",
      "238 119.69486403822899\n",
      "239 254.99092945456505\n",
      "240 75.46689498782158\n",
      "241 393.09562373906374\n",
      "242 232.308551197052\n",
      "243 332.3459889739752\n",
      "244 288.9861726549934\n",
      "245 179.80858504772186\n",
      "246 301.24343134582045\n",
      "247 267.46017771959305\n",
      "248 242.06551212072372\n",
      "249 366.4049381017685\n"
     ]
    }
   ],
   "source": [
    "##Using Batch Gradient\n",
    "batch_size=100\n",
    "for i in range(250):\n",
    "    num_batches=int(mnist.train.num_examples/batch_size)\n",
    "    total_cost=0\n",
    "    for j in range(num_batches):\n",
    "        batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "        c,_=sess.run([cost,optimize], feed_dict={x:batch_x, y:batch_y})\n",
    "        total_cost+=c\n",
    "    print(i,total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##Without using batch gradient and iterations\n",
    "#c,_=sess.run([cost,optimize], feed_dict={x:mnist.train.images, y:mnist.train.labels})\n",
    "#c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pred=tf.argmax(pred,axis=1)\n",
    "n_labels=tf.argmax(y,axis=1)\n",
    "n_correct=tf.equal(n_pred,n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8, 2, 4, ..., 8, 3, 2], dtype=int64),\n",
       " array([8, 2, 4, ..., 8, 3, 2], dtype=int64),\n",
       " array([ True,  True,  True, ...,  True,  True,  True]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_eval,labels_eval,correct_pred=sess.run([n_pred,n_labels,n_correct], feed_dict={x:mnist.train.images, y:mnist.train.labels})\n",
    "pred_eval,labels_eval,correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54996"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.99272727272728 %\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "Accuracy=100*(correct_pred.sum()/mnist.train.num_examples)\n",
    "print(Accuracy,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
