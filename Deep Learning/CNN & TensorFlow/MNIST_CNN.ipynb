{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-d47a824d614e>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Ishan SS\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Ishan SS\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNISt_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Ishan SS\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNISt_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Ishan SS\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNISt_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNISt_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Ishan SS\\Anaconda3\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets(\"MNISt_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_width=28\n",
    "input_height=28\n",
    "input_channels=1\n",
    "input_pixels=784\n",
    "\n",
    "n_conv1=32 #Convolution layer 1\n",
    "k_conv1=5 #Filter size of conv1\n",
    "stride_conv1=1 #Stride size for conv1\n",
    "\n",
    "max_pool1_k=2 #Max Poolsize for pool1\n",
    "\n",
    "n_conv2=64 #Convolution layer 2\n",
    "k_conv2=5 #Filter size of conv2\n",
    "stride_conv2=1 #Stride size for conv2\n",
    "\n",
    "max_pool2_k=2 #Max Poolsize for pool2\n",
    "\n",
    "n_hidden=1024\n",
    "n_op=10\n",
    "\n",
    "input_to_hidden=(input_width//(max_pool1_k*max_pool2_k))*(input_height//(max_pool1_k*max_pool2_k))*n_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights={\n",
    "    \"wc1\":tf.Variable(tf.random_normal([k_conv1,k_conv1,input_channels,n_conv1])),\n",
    "    \"wc2\":tf.Variable(tf.random_normal([k_conv2,k_conv2,n_conv1,n_conv2])),\n",
    "    \"wh\":tf.Variable(tf.random_normal([input_to_hidden,n_hidden])),\n",
    "    \"wo\":tf.Variable(tf.random_normal([n_hidden,n_op]))\n",
    "}\n",
    "biases={\n",
    "    \"bc1\":tf.Variable(tf.random_normal([n_conv1])),\n",
    "    \"bc2\":tf.Variable(tf.random_normal([n_conv2])),\n",
    "    \"bh\":tf.Variable(tf.random_normal([n_hidden])),\n",
    "    \"bo\":tf.Variable(tf.random_normal([n_op]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(x,weights,bias,strides=1):\n",
    "    out=tf.nn.conv2d(x,weights,padding=\"SAME\",strides=[1,strides,strides,1])\n",
    "    out=tf.nn.bias_add(out,bias)\n",
    "    out=tf.nn.relu(out)\n",
    "    return out\n",
    "\n",
    "def max_pooling(x,k=2):\n",
    "    return tf.nn.max_pool(x,padding=\"SAME\",ksize=[1,k,k,1],strides=[1,k,k,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(x,weights,biases):\n",
    "    x=tf.reshape(x,shape=[-1,input_height,input_width,input_channels])\n",
    "    conv1=conv(x,weights['wc1'],biases['bc1'],stride_conv1)\n",
    "    pool1=max_pooling(conv1,max_pool1_k)\n",
    "    \n",
    "    conv2=conv(pool1,weights['wc2'],biases['bc2'],stride_conv2)\n",
    "    pool2=max_pooling(conv2,max_pool2_k)\n",
    "    \n",
    "    hidden_input=tf.reshape(pool2,shape=[-1,input_to_hidden])\n",
    "    hidden_input_term=tf.add(tf.matmul(hidden_input,weights['wh']),biases['bh'])\n",
    "    hidden_output=tf.nn.relu(hidden_input_term)\n",
    "    \n",
    "    output=tf.add(tf.matmul(hidden_output,weights['wo']),biases['bo']) #using identity function at output layer\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Add_1:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=tf.placeholder(\"float\",[None,input_pixels])\n",
    "y=tf.placeholder(tf.int32,[None,n_op])\n",
    "pred=cnn(x,weights,biases)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mean:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred ,labels=y))\n",
    "cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "optimize=optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1772894.6029510498\n",
      "1 293959.000875175\n",
      "2 175019.84646511078\n",
      "3 117682.71611082554\n",
      "4 84850.28679212928\n",
      "5 61864.130159810185\n",
      "6 47181.00113943964\n",
      "7 35537.559651218704\n",
      "8 28441.511630814523\n",
      "9 25296.62510641992\n",
      "10 19477.413543647384\n",
      "11 17585.541860307807\n",
      "12 15736.429654978856\n",
      "13 11489.283857365572\n",
      "14 13924.141924135387\n",
      "15 9331.275364041328\n",
      "16 11394.694885075092\n",
      "17 9235.137040747446\n",
      "18 7512.649440016747\n",
      "19 8078.455491418019\n",
      "20 7206.063643977046\n",
      "21 6078.958040764779\n",
      "22 6288.820250868797\n",
      "23 4983.4244946576655\n",
      "24 4750.055147517805\n",
      "25 6616.806877313248\n",
      "26 4162.868663147994\n",
      "27 4682.251107096672\n",
      "28 4590.409471295774\n",
      "29 3856.0012774169445\n",
      "30 3281.9258915781975\n",
      "31 3448.8366795778275\n",
      "32 5132.490847527981\n",
      "33 2657.0581536889076\n",
      "34 2635.0391916036606\n",
      "35 2733.4179230332375\n",
      "36 3531.751641474664\n",
      "37 2217.4821235463023\n",
      "38 2944.0313799381256\n",
      "39 2988.3436647093295\n",
      "40 1504.0883903503418\n",
      "41 2444.910477157682\n",
      "42 2091.6504378986356\n",
      "43 2484.243042534843\n",
      "44 1589.8606748580933\n",
      "45 1965.999671925325\n",
      "46 2461.4023280218244\n",
      "47 2477.940563350916\n",
      "48 2065.9531806111336\n",
      "49 1314.2062514722347\n",
      "50 1243.1811006516218\n",
      "51 1693.3459893092513\n",
      "52 1263.0802356004715\n",
      "53 2013.206270456314\n",
      "54 1841.169275383243\n",
      "55 1872.6987486481667\n",
      "56 1356.3114564561845\n",
      "57 1361.7045732736588\n",
      "58 1204.259442806244\n",
      "59 1368.7209187466651\n",
      "60 1970.0799868106842\n",
      "61 1344.062455534935\n",
      "62 1348.5051460266113\n",
      "63 1209.9248074293137\n",
      "64 1446.8418247252703\n",
      "65 1728.3207122766971\n",
      "66 1281.2890704870224\n",
      "67 933.8714153355104\n",
      "68 1296.1846517007798\n",
      "69 1172.216622961343\n",
      "70 979.9879933968186\n",
      "71 1442.1608941886443\n",
      "72 771.127150561264\n",
      "73 1473.1761144399643\n",
      "74 1271.6192289441824\n",
      "75 162.33880013227463\n",
      "76 1233.458029806614\n",
      "77 1497.5688439011574\n",
      "78 1307.4713686704636\n",
      "79 980.0356224477291\n",
      "80 1043.3381280303001\n",
      "81 1441.6020325422287\n",
      "82 264.62318110466003\n",
      "83 944.7227966189384\n",
      "84 957.2782163619995\n",
      "85 633.3500324189663\n",
      "86 583.6747556328773\n",
      "87 1211.1834779977798\n",
      "88 428.9559289216995\n",
      "89 869.4972185194492\n",
      "90 831.8675532420166\n",
      "91 1311.037840456961\n",
      "92 1262.7758685648441\n",
      "93 427.5577235221863\n",
      "94 575.1680954694748\n",
      "95 953.44623285532\n",
      "96 911.7046325206757\n",
      "97 838.1751222610474\n",
      "98 746.9717884063721\n",
      "99 661.2989920377731\n",
      "100 329.16940557956696\n",
      "101 1065.7260724306107\n",
      "102 898.7666780483412\n",
      "103 1057.4258714169264\n",
      "104 520.9585808515549\n",
      "105 315.9908185005188\n",
      "106 693.5527077317238\n",
      "107 872.3623483330011\n",
      "108 401.1278785467148\n",
      "109 1602.2625074483894\n",
      "110 845.7587161064148\n",
      "111 338.7809603214264\n",
      "112 87.14524841308594\n",
      "113 1141.9247946739197\n",
      "114 505.5475183725357\n",
      "115 769.1802767068148\n",
      "116 478.58822524547577\n",
      "117 787.2679457963095\n",
      "118 642.1752368658781\n",
      "119 270.2600362300873\n",
      "120 904.7605650424957\n",
      "121 488.8062605857849\n",
      "122 582.7091452591121\n",
      "123 504.91466879844666\n",
      "124 285.5096526145935\n",
      "125 691.1382923126221\n",
      "126 701.2893211841583\n",
      "127 559.2219844521023\n",
      "128 563.0766635632424\n",
      "129 389.0708286613226\n",
      "130 469.9885989513714\n",
      "131 504.02705705165863\n",
      "132 706.4121079444885\n",
      "133 342.3555598258972\n",
      "134 851.9719349145889\n",
      "135 820.0634155273438\n",
      "136 170.24935340881348\n",
      "137 569.5665763020515\n",
      "138 407.5015913248062\n",
      "139 570.6550784111023\n",
      "140 456.9475875198841\n",
      "141 205.61636543273926\n",
      "142 463.820666968693\n",
      "143 809.8710907330365\n",
      "144 322.31721556186676\n",
      "145 369.00205075740814\n",
      "146 792.8684251308441\n",
      "147 345.84886759519577\n",
      "148 544.755980014801\n",
      "149 406.9661554098129\n",
      "150 751.3279612660408\n",
      "151 263.6165657043457\n",
      "152 345.11763203144073\n",
      "153 730.5693690371099\n",
      "154 470.2192597389221\n",
      "155 416.7819963693619\n",
      "156 438.1082351207733\n",
      "157 168.28964805603027\n",
      "158 707.6888493969991\n",
      "159 545.2460961341858\n",
      "160 347.5098603963852\n",
      "161 675.9707431793213\n",
      "162 362.77586084604263\n",
      "163 383.006817817688\n",
      "164 222.24677634239197\n",
      "165 845.7977586388588\n",
      "166 462.8521628379822\n",
      "167 373.67767655849457\n",
      "168 398.04701352119446\n",
      "169 287.26465141773224\n",
      "170 202.75064373016357\n",
      "171 368.0778708457947\n",
      "172 611.4188937300642\n",
      "173 592.4330368041992\n",
      "174 208.68795204162598\n",
      "175 482.72360396385193\n",
      "176 419.90285140275955\n",
      "177 794.7831047773361\n",
      "178 162.9412498474121\n",
      "179 487.27098041027784\n",
      "180 395.82800698280334\n",
      "181 741.2595431804657\n",
      "182 132.5371305346489\n",
      "183 114.55904388427734\n",
      "184 356.77452260255814\n",
      "185 0.0\n",
      "186 0.0\n",
      "187 0.0\n",
      "188 0.0\n",
      "189 0.0\n",
      "190 0.0\n",
      "191 0.0\n",
      "192 0.0\n",
      "193 0.0\n",
      "194 0.0\n",
      "195 0.0\n",
      "196 0.0\n",
      "197 0.0\n",
      "198 0.0\n",
      "199 0.0\n",
      "200 0.0\n",
      "201 0.0\n",
      "202 0.0\n",
      "203 0.0\n",
      "204 0.0\n",
      "205 0.0\n",
      "206 0.0\n",
      "207 0.0\n",
      "208 0.0\n",
      "209 0.0\n",
      "210 0.0\n",
      "211 0.0\n",
      "212 0.0\n",
      "213 0.0\n",
      "214 0.0\n",
      "215 0.0\n",
      "216 0.0\n",
      "217 0.0\n",
      "218 0.0\n",
      "219 0.0\n",
      "220 0.0\n",
      "221 0.0\n",
      "222 0.0\n",
      "223 0.0\n",
      "224 0.0\n",
      "225 0.0\n",
      "226 0.0\n",
      "227 0.0\n",
      "228 0.0\n",
      "229 0.0\n",
      "230 0.0\n",
      "231 0.0\n",
      "232 0.0\n",
      "233 0.0\n",
      "234 0.0\n",
      "235 0.0\n",
      "236 0.0\n",
      "237 0.0\n",
      "238 0.0\n",
      "239 0.0\n",
      "240 0.0\n",
      "241 0.0\n",
      "242 0.0\n",
      "243 0.0\n",
      "244 0.0\n",
      "245 0.0\n",
      "246 0.0\n",
      "247 0.0\n",
      "248 0.0\n",
      "249 0.0\n"
     ]
    }
   ],
   "source": [
    "##Using Batch Gradient\n",
    "batch_size=100\n",
    "for i in range(250):\n",
    "    num_batches=int(mnist.train.num_examples/batch_size)\n",
    "    total_cost=0\n",
    "    for j in range(num_batches):\n",
    "        batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "        c,_=sess.run([cost,optimize], feed_dict={x:batch_x, y:batch_y})\n",
    "        total_cost+=c\n",
    "    print(i,total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pred=tf.argmax(pred,axis=1)\n",
    "n_labels=tf.argmax(y,axis=1)\n",
    "n_correct=tf.equal(n_pred,n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9, 5, 4, ..., 1, 5, 9], dtype=int64),\n",
       " array([9, 5, 4, ..., 1, 5, 9], dtype=int64),\n",
       " array([ True,  True,  True, ...,  True,  True,  True]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_eval,labels_eval,correct_pred=sess.run([n_pred,n_labels,n_correct], feed_dict={x:mnist.train.images, y:mnist.train.labels})\n",
    "pred_eval,labels_eval,correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0 %\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "Accuracy=100*(correct_pred.sum()/mnist.train.num_examples)\n",
    "print(Accuracy,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
